{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SWMAL Exercise\n",
    "\n",
    "\n",
    "## Hyperparameters and Gridsearch \n",
    "\n",
    "When instantiating a Scikit-learn model in python most or all constructor parameters have _default_ values. These values are not part of the internal model and are hence called ___hyperparameters___---in contrast to _normal_ model parameters, for example the neuron weights, $\\mathbf w$, for an `MLP` model.\n",
    "\n",
    "### Manual Tuning Hyperparameters\n",
    "\n",
    "Below is an example of the python constructor for the support-vector classifier `sklearn.svm.SVC`, with say the `kernel` hyperparameter having the default value `'rbf'`. If you should choose, what would you set it to other than `'rbf'`? \n",
    "\n",
    "```python\n",
    "class sklearn.svm.SVC(\n",
    "    C=1.0, \n",
    "    kernel=â€™rbfâ€™, \n",
    "    degree=3,\n",
    "    gamma=â€™auto_deprecatedâ€™, \n",
    "    coef0=0.0, \n",
    "    shrinking=True, \n",
    "    probability=False, \n",
    "    tol=0.001, \n",
    "    cache_size=200, \n",
    "    class_weight=None, \n",
    "    verbose=False, \n",
    "    max_iter=-1, \n",
    "    decision_function_shape=â€™ovrâ€™, \n",
    "    random_state=None\n",
    "  )\n",
    "```  \n",
    "\n",
    "The default values might be a sensible general starting point, but for your data, you might want to optimize the hyperparameters to yield a better result. \n",
    "\n",
    "To be able to set `kernel` to a sensible value you need to go into the documentation for the `SVC` and understand what the kernel parameter represents, and what values it can be set to, and you need to understand the consequences of setting `kernel` to something different than the default...and the story repeats for every other hyperparameter!\n",
    "\n",
    "### Brute Force  Search\n",
    "\n",
    "An alternative to this structured, but time-consuming approach, is just to __brute-force__ a search of interesting hyperparameters, and  choose the 'best' parameters according to a fit-predict and some score, say 'f1'. \n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/SWMAL/L09/Figs/gridsearch.png\"  alt=\"WARNING: could not get image from server.\"  style=\"width:350px\">\n",
    "<small><em>\n",
    "    <center> Conceptual graphical view of grid search for two distinct hyperparameters. </center> \n",
    "    <center> Notice that you would normally search hyperparameters like `alpha` with an exponential range, say [0.01, 0.1, 1, 10] or similar.</center>\n",
    "</em></small>\n",
    "\n",
    "Now, you just pick out some hyperparameters, that you figure are important, set them to a suitable range, say\n",
    "\n",
    "```python\n",
    "    'kernel':('linear', 'rbf'), \n",
    "    'C':[1, 10]\n",
    "```\n",
    "and fire up a full (grid) search on this hyperparameter set, that will try out all your specified combination of `kernel` and `C` for the model, and then prints the hyperparameter set with the highest score...\n",
    "\n",
    "The demo code below sets up some of our well known 'hello-world' data and then run a _grid search_ on a particular model, here a _support-vector classifier_ (SVC)\n",
    "\n",
    "Other models and datasets  ('mnist', 'iris', 'moon') can also be examined.\n",
    "\n",
    "### Qa Explain GridSearchCV\n",
    "\n",
    "There are two code cells below: 1) function setup, 2) the actual grid-search.\n",
    "\n",
    "Review the code cells and write a __short__ summary. Mainly focus on __cell 2__, but dig into cell 1 if you find it interesting (notice the use of local-function, a nifty feature in python).\n",
    "  \n",
    "In detail, examine the lines:  \n",
    "  \n",
    "```python\n",
    "grid_tuned = GridSearchCV(model, tuning_parameters, ..\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "..\n",
    "FullReport(grid_tuned , X_test, y_test, time_gridsearch)\n",
    "```\n",
    "and write a short description of how the `GridSeachCV` works: explain how the search parameter set is created and the overall search mechanism is functioning (without going into too much detail).\n",
    "\n",
    "What role does the parameter `scoring='f1_micro'` play in the `GridSearchCV`, and what does `n_jobs=-1` mean? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK(function setup, hope MNIST loads works, seem best if you got Keras or Tensorflow installed!)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa, code review..cell 1) function setup\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn import datasets\n",
    "\n",
    "from libitmal import dataloaders as itmaldataloaders # Needed for load of iris, moon and mnist\n",
    "\n",
    "currmode=\"N/A\" # GLOBAL var!\n",
    "\n",
    "def SearchReport(model): \n",
    "    \n",
    "    def GetBestModelCTOR(model, best_params):\n",
    "        def GetParams(best_params):\n",
    "            ret_str=\"\"          \n",
    "            for key in sorted(best_params):\n",
    "                value = best_params[key]\n",
    "                temp_str = \"'\" if str(type(value))==\"<class 'str'>\" else \"\"\n",
    "                if len(ret_str)>0:\n",
    "                    ret_str += ','\n",
    "                ret_str += f'{key}={temp_str}{value}{temp_str}'  \n",
    "            return ret_str          \n",
    "        try:\n",
    "            param_str = GetParams(best_params)\n",
    "            return type(model).__name__ + '(' + param_str + ')' \n",
    "        except:\n",
    "            return \"N/A(1)\"\n",
    "        \n",
    "    print(\"\\nBest model set found on train set:\")\n",
    "    print()\n",
    "    print(f\"\\tbest parameters={model.best_params_}\")\n",
    "    print(f\"\\tbest '{model.scoring}' score={model.best_score_}\")\n",
    "    print(f\"\\tbest index={model.best_index_}\")\n",
    "    print()\n",
    "    print(f\"Best estimator CTOR:\")\n",
    "    print(f\"\\t{model.best_estimator_}\")\n",
    "    print()\n",
    "    try:\n",
    "        print(f\"Grid scores ('{model.scoring}') on development set:\")\n",
    "        means = model.cv_results_['mean_test_score']\n",
    "        stds  = model.cv_results_['std_test_score']\n",
    "        i=0\n",
    "        for mean, std, params in zip(means, stds, model.cv_results_['params']):\n",
    "            print(\"\\t[%2d]: %0.3f (+/-%0.03f) for %r\" % (i, mean, std * 2, params))\n",
    "            i += 1\n",
    "    except:\n",
    "        print(\"WARNING: the random search do not provide means/stds\")\n",
    "    \n",
    "    global currmode                \n",
    "    assert \"f1_micro\"==str(model.scoring), f\"come on, we need to fix the scoring to be able to compare model-fits! Your scoreing={str(model.scoring)}...remember to add scoring='f1_micro' to the search\"   \n",
    "    return f\"best: dat={currmode}, score={model.best_score_:0.5f}, model={GetBestModelCTOR(model.estimator,model.best_params_)}\", model.best_estimator_ \n",
    "\n",
    "def ClassificationReport(model, X_test, y_test, target_names=None):\n",
    "    assert X_test.shape[0]==y_test.shape[0]\n",
    "    print(\"\\nDetailed classification report:\")\n",
    "    print(\"\\tThe model is trained on the full development set.\")\n",
    "    print(\"\\tThe scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, model.predict(X_test)                 \n",
    "    print(classification_report(y_true, y_pred, target_names))\n",
    "    print()\n",
    "    \n",
    "def FullReport(model, X_test, y_test, t):\n",
    "    print(f\"SEARCH TIME: {t:0.2f} sec\")\n",
    "    beststr, bestmodel = SearchReport(model)\n",
    "    ClassificationReport(model, X_test, y_test)    \n",
    "    print(f\"CTOR for best model: {bestmodel}\\n\")\n",
    "    print(f\"{beststr}\\n\")\n",
    "    return beststr, bestmodel\n",
    "    \n",
    "def LoadAndSetupData(mode, test_size=0.3):\n",
    "    assert test_size>=0.0 and test_size<=1.0\n",
    "    \n",
    "    def ShapeToString(Z):\n",
    "        n = Z.ndim\n",
    "        s = \"(\"\n",
    "        for i in range(n):\n",
    "            s += f\"{Z.shape[i]:5d}\"\n",
    "            if i+1!=n:\n",
    "                s += \";\"\n",
    "        return s+\")\"\n",
    "\n",
    "    global currmode\n",
    "    currmode=mode\n",
    "    print(f\"DATA: {currmode}..\")\n",
    "    \n",
    "    if mode=='moon':\n",
    "        X, y = itmaldataloaders.MOON_GetDataSet(n_samples=5000, noise=0.2)\n",
    "        itmaldataloaders.MOON_Plot(X, y)\n",
    "    elif mode=='mnist':\n",
    "        X, y = itmaldataloaders.MNIST_GetDataSet(load_mode=0)\n",
    "        if X.ndim==3:\n",
    "            X=np.reshape(X, (X.shape[0], -1))\n",
    "    elif mode=='iris':\n",
    "        X, y = itmaldataloaders.IRIS_GetDataSet()\n",
    "    else:\n",
    "        raise ValueError(f\"could not load data for that particular mode='{mode}', only 'moon'/'mnist'/'iris' supported\")\n",
    "        \n",
    "    print(f'  org. data:  X.shape      ={ShapeToString(X)}, y.shape      ={ShapeToString(y)}')\n",
    "\n",
    "    assert X.ndim==2\n",
    "    assert X.shape[0]==y.shape[0]\n",
    "    assert y.ndim==1 or (y.ndim==2 and y.shape[1]==0)    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=0, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f'  train data: X_train.shape={ShapeToString(X_train)}, y_train.shape={ShapeToString(y_train)}')\n",
    "    print(f'  test data:  X_test.shape ={ShapeToString(X_test)}, y_test.shape ={ShapeToString(y_test)}')\n",
    "    print()\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "print('OK(function setup, hope MNIST loads works, seem best if you got Keras or Tensorflow installed!)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: iris..\n",
      "  org. data:  X.shape      =(  150;    4), y.shape      =(  150)\n",
      "  train data: X_train.shape=(  105;    4), y_train.shape=(  105)\n",
      "  test data:  X_test.shape =(   45;    4), y_test.shape =(   45)\n",
      "\n",
      "SEARCH TIME: 2.20 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'C': 1, 'kernel': 'linear'}\n",
      "\tbest 'f1_micro' score=0.9714285714285715\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.962 (+/-0.093) for {'C': 0.1, 'kernel': 'linear'}\n",
      "\t[ 1]: 0.371 (+/-0.038) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "\t[ 2]: 0.971 (+/-0.047) for {'C': 1, 'kernel': 'linear'}\n",
      "\t[ 3]: 0.695 (+/-0.047) for {'C': 1, 'kernel': 'rbf'}\n",
      "\t[ 4]: 0.952 (+/-0.085) for {'C': 10, 'kernel': 'linear'}\n",
      "\t[ 5]: 0.924 (+/-0.097) for {'C': 10, 'kernel': 'rbf'}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.97      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n",
      "\n",
      "CTOR for best model: SVC(C=1, gamma=0.001, kernel='linear')\n",
      "\n",
      "best: dat=iris, score=0.97143, model=SVC(C=1,kernel='linear')\n",
      "\n",
      "OK(grid-search)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marius\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "# TODO: Qa, code review..cell 2) the actual grid-search\n",
    "\n",
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'iris')  # 'iris', 'moon', or 'mnist'\n",
    "\n",
    "# Setup search parameters\n",
    "model = svm.SVC(\n",
    "    gamma=0.001\n",
    ")  # NOTE: gamma=\"scale\" does not work in older Scikit-learn frameworks,\n",
    "# FIX:  replace with model = svm.SVC(gamma=0.001)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'kernel': ('linear', 'rbf'), \n",
    "    'C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "CV = 5\n",
    "VERBOSE = 0\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "start = time()\n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=CV,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=VERBOSE,\n",
    "                          n_jobs=-1)\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qb Hyperparameter Grid Search using an SDG classifier\n",
    "\n",
    "Now, replace the `svm.SVC` model with an `SGDClassifier` and a suitable set of the hyperparameters for that model.\n",
    "\n",
    "You need at least four or five different hyperparameters from the `SGDClassifier` in the search-space before it begins to take considerable compute time doing the full grid search.\n",
    "\n",
    "So, repeat the search with the `SGDClassifier`, and be sure to add enough hyperparameters to the grid-search, such that the search takes a considerable time to run, that is a couple of minutes or up to some hours.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 3.22 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\tbest 'f1_micro' score=0.9523809523809523\n",
      "\tbest index=516\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(early_stopping=True, eta0=0.05, learning_rate='adaptive',\n",
      "              max_iter=100, penalty='l1', random_state=42, warm_start=True)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[ 1]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[ 2]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[ 3]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[ 4]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[ 5]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[ 6]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[ 7]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[ 8]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[ 9]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[10]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[11]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[12]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[13]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[14]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[15]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[16]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[17]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[18]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[19]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[20]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[21]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[22]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[23]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[24]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[25]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[26]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[27]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[28]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[29]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[30]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[31]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[32]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[33]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[34]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[35]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[36]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[37]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[38]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[39]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[40]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[41]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[42]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[43]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[44]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[45]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[46]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[47]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[48]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[49]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[50]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[51]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[52]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[53]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[54]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[55]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[56]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[57]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[58]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[59]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[60]: 0.743 (+/-0.166) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[61]: 0.743 (+/-0.166) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[62]: 0.743 (+/-0.166) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[63]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[64]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[65]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[66]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[67]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[68]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[69]: 0.733 (+/-0.177) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[70]: 0.733 (+/-0.177) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[71]: 0.733 (+/-0.177) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[72]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[73]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[74]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[75]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[76]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[77]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[78]: 0.733 (+/-0.177) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[79]: 0.733 (+/-0.177) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[80]: 0.733 (+/-0.177) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[81]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[82]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[83]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[84]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[85]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[86]: 0.724 (+/-0.093) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[87]: 0.733 (+/-0.177) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[88]: 0.733 (+/-0.177) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[89]: 0.733 (+/-0.177) for {'eta0': 0.0005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[90]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[91]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[92]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[93]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[94]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[95]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[96]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[97]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[98]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[99]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[100]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[101]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[102]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[103]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[104]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[105]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[106]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[107]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[108]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[109]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[110]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[111]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[112]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[113]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[114]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[115]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[116]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[117]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[118]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[119]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[120]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[121]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[122]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[123]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[124]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[125]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[126]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[127]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[128]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[129]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[130]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[131]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[132]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[133]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[134]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[135]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[136]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[137]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[138]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[139]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[140]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[141]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[142]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[143]: 0.371 (+/-0.038) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[144]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[145]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[146]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[147]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[148]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[149]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[150]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[151]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[152]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[153]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[154]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[155]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[156]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[157]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[158]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[159]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[160]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[161]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[162]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[163]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[164]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[165]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[166]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[167]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[168]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[169]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[170]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[171]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[172]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[173]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[174]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[175]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[176]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[177]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[178]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[179]: 0.695 (+/-0.047) for {'eta0': 0.0005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[180]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[181]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[182]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[183]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[184]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[185]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[186]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[187]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[188]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[189]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[190]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[191]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[192]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[193]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[194]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[195]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[196]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[197]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[198]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[199]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[200]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[201]: 0.771 (+/-0.236) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[202]: 0.771 (+/-0.236) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[203]: 0.771 (+/-0.236) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[204]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[205]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[206]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[207]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[208]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[209]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[210]: 0.771 (+/-0.236) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[211]: 0.771 (+/-0.236) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[212]: 0.771 (+/-0.236) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[213]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[214]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[215]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[216]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[217]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[218]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[219]: 0.771 (+/-0.236) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[220]: 0.771 (+/-0.236) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[221]: 0.771 (+/-0.236) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[222]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[223]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[224]: 0.762 (+/-0.241) for {'eta0': 0.005, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[225]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[226]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[227]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[228]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[229]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[230]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[231]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[232]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[233]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[234]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[235]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[236]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[237]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[238]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[239]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[240]: 0.743 (+/-0.166) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[241]: 0.743 (+/-0.166) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[242]: 0.743 (+/-0.166) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[243]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[244]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[245]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[246]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[247]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[248]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[249]: 0.733 (+/-0.177) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[250]: 0.733 (+/-0.177) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[251]: 0.733 (+/-0.177) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[252]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[253]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[254]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[255]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[256]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[257]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[258]: 0.733 (+/-0.177) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[259]: 0.733 (+/-0.177) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[260]: 0.733 (+/-0.177) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[261]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[262]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[263]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[264]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[265]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[266]: 0.724 (+/-0.093) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[267]: 0.733 (+/-0.177) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[268]: 0.733 (+/-0.177) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[269]: 0.733 (+/-0.177) for {'eta0': 0.005, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[270]: 0.467 (+/-0.279) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[271]: 0.467 (+/-0.279) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[272]: 0.467 (+/-0.279) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[273]: 0.467 (+/-0.279) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[274]: 0.467 (+/-0.279) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[275]: 0.467 (+/-0.279) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[276]: 0.467 (+/-0.279) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[277]: 0.467 (+/-0.279) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[278]: 0.467 (+/-0.279) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[279]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[280]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[281]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[282]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[283]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[284]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[285]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[286]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[287]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[288]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[289]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[290]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[291]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[292]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[293]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[294]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[295]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[296]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[297]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[298]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[299]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[300]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[301]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[302]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[303]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[304]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[305]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[306]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[307]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[308]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[309]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[310]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[311]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[312]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[313]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[314]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[315]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[316]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[317]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[318]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[319]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[320]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[321]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[322]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[323]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[324]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[325]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[326]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[327]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[328]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[329]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[330]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[331]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[332]: 0.695 (+/-0.047) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[333]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[334]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[335]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[336]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[337]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[338]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[339]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[340]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[341]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[342]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[343]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[344]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[345]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[346]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[347]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[348]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[349]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[350]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[351]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[352]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[353]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[354]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[355]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[356]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[357]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[358]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[359]: 0.714 (+/-0.085) for {'eta0': 0.005, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[360]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[361]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[362]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[363]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[364]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[365]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[366]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[367]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[368]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[369]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[370]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[371]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[372]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[373]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[374]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[375]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[376]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[377]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[378]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[379]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[380]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[381]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[382]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[383]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[384]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[385]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[386]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[387]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[388]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[389]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[390]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[391]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[392]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[393]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[394]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[395]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[396]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[397]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[398]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[399]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[400]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[401]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[402]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[403]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[404]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'constant', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[405]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[406]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[407]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[408]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[409]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[410]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[411]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[412]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[413]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[414]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[415]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[416]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[417]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[418]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[419]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[420]: 0.743 (+/-0.166) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[421]: 0.743 (+/-0.166) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[422]: 0.743 (+/-0.166) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[423]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[424]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[425]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[426]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[427]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[428]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[429]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[430]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[431]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[432]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[433]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[434]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[435]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[436]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[437]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[438]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[439]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[440]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[441]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[442]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[443]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[444]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[445]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[446]: 0.724 (+/-0.093) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[447]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[448]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[449]: 0.733 (+/-0.177) for {'eta0': 0.05, 'learning_rate': 'optimal', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[450]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[451]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[452]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[453]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[454]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[455]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[456]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[457]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[458]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[459]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[460]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[461]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[462]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[463]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[464]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[465]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[466]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[467]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[468]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[469]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[470]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[471]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[472]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[473]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[474]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[475]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[476]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[477]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[478]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[479]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[480]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[481]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[482]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[483]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[484]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[485]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[486]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[487]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[488]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[489]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[490]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[491]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[492]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[493]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[494]: 0.695 (+/-0.047) for {'eta0': 0.05, 'learning_rate': 'invscaling', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[495]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[496]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[497]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[498]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[499]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[500]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[501]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[502]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[503]: 0.686 (+/-0.076) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[504]: 0.857 (+/-0.104) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[505]: 0.857 (+/-0.104) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[506]: 0.857 (+/-0.104) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[507]: 0.848 (+/-0.140) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[508]: 0.848 (+/-0.140) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[509]: 0.848 (+/-0.140) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[510]: 0.857 (+/-0.104) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[511]: 0.857 (+/-0.104) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[512]: 0.857 (+/-0.104) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[513]: 0.943 (+/-0.071) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[514]: 0.943 (+/-0.071) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[515]: 0.943 (+/-0.071) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[516]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[517]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[518]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[519]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[520]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[521]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 100, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[522]: 0.943 (+/-0.071) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[523]: 0.943 (+/-0.071) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[524]: 0.943 (+/-0.071) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[525]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[526]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[527]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[528]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[529]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[530]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 1000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\t[531]: 0.943 (+/-0.071) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.001}\n",
      "\t[532]: 0.943 (+/-0.071) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l2', 'tol': 0.0001}\n",
      "\t[533]: 0.943 (+/-0.071) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l2', 'tol': 1e-05}\n",
      "\t[534]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.001}\n",
      "\t[535]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l1', 'tol': 0.0001}\n",
      "\t[536]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'l1', 'tol': 1e-05}\n",
      "\t[537]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.001}\n",
      "\t[538]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 0.0001}\n",
      "\t[539]: 0.952 (+/-0.060) for {'eta0': 0.05, 'learning_rate': 'adaptive', 'max_iter': 10000, 'penalty': 'elasticnet', 'tol': 1e-05}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(early_stopping=True, eta0=0.05, learning_rate='adaptive',\n",
      "              max_iter=100, penalty='l1', random_state=42, warm_start=True)\n",
      "\n",
      "best: dat=iris, score=0.95238, model=SGDClassifier(eta0=0.05,learning_rate='adaptive',max_iter=100,penalty='l1',tol=0.001)\n",
      "\n",
      "OK(grid-search)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marius\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "# Setup search parameters\n",
    "model = SGDClassifier(max_iter=1,\n",
    "                       eta0=0.05,\n",
    "                       early_stopping=True,\n",
    "                       warm_start=True,\n",
    "                       random_state=42)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'max_iter': [1, 10, 100, 1000, 10000], \n",
    "    'eta0': [0.0005, 0.005, 0.05], \n",
    "    'penalty': ('l2', 'l1', 'elasticnet'),\n",
    "    'tol': [0.001, 0.0001, 0.00001],\n",
    "    'learning_rate': ('constant', 'optimal', 'invscaling', 'adaptive')\n",
    "}\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "start = time()\n",
    "grid_tuned = GridSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=5,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=0,\n",
    "                          n_jobs=-1)\n",
    "grid_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(grid_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qc Hyperparameter Random  Search using an SDG classifier\n",
    "\n",
    "Now, add code to run a `RandomizedSearchCV` instead.\n",
    "\n",
    "<img src=\"https://itundervisning.ase.au.dk/SWMAL/L09/Figs/randomsearch.png\" alt=\"WARNING: could not get image from server.\"  style=\"width:350px\" >\n",
    "<small><em>\n",
    "    <center> Conceptual graphical view of randomized search for two distinct hyperparameters. </center> \n",
    "</em></small>\n",
    "\n",
    "Use these default parameters for the random search, similar to the default parameters for the grid search\n",
    "\n",
    "```python\n",
    "random_tuned = RandomizedSearchCV(\n",
    "    model, \n",
    "    tuning_parameters, \n",
    "    n_iter=20, \n",
    "    random_state=42, \n",
    "    cv=CV, \n",
    "    scoring='f1_micro', \n",
    "    verbose=VERBOSE, \n",
    "    n_jobs=-1\n",
    ")\n",
    "```\n",
    "\n",
    "but with the two new parameters, `n_iter` and `random_state` added. Since the search-type is now random, the `random_state` gives sense, but essential to random search is the new `n_tier` parameter.\n",
    "\n",
    "So: investigate the `n_iter` parameter...in code and write a conceptual explanation  in text.\n",
    "\n",
    "Comparison of time (seconds) to complete `GridSearch` versus `RandomizedSearchCV`, does not necessarily give any sense, if your grid search completes in a few seconds (as for the iris tiny-data). You need a search that runs for minutes, hours, or days.\n",
    "\n",
    "But you could compare the best-tuned parameter set and best scoring for the two methods. Is the random search best model close to the grid search?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 0.21 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'tol': 1e-05, 'penalty': 'elasticnet', 'max_iter': 100, 'learning_rate': 'adaptive', 'eta0': 0.05}\n",
      "\tbest 'f1_micro' score=0.9523809523809523\n",
      "\tbest index=2\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(early_stopping=True, eta0=0.05, learning_rate='adaptive',\n",
      "              max_iter=100, penalty='elasticnet', random_state=42, tol=1e-05,\n",
      "              warm_start=True)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.695 (+/-0.047) for {'tol': 0.0001, 'penalty': 'l1', 'max_iter': 1, 'learning_rate': 'optimal', 'eta0': 0.005}\n",
      "\t[ 1]: 0.695 (+/-0.047) for {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 1000, 'learning_rate': 'optimal', 'eta0': 0.0005}\n",
      "\t[ 2]: 0.952 (+/-0.060) for {'tol': 1e-05, 'penalty': 'elasticnet', 'max_iter': 100, 'learning_rate': 'adaptive', 'eta0': 0.05}\n",
      "\t[ 3]: 0.724 (+/-0.093) for {'tol': 1e-05, 'penalty': 'l1', 'max_iter': 10000, 'learning_rate': 'optimal', 'eta0': 0.0005}\n",
      "\t[ 4]: 0.695 (+/-0.047) for {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 100, 'learning_rate': 'invscaling', 'eta0': 0.05}\n",
      "\t[ 5]: 0.724 (+/-0.093) for {'tol': 1e-05, 'penalty': 'l1', 'max_iter': 1000, 'learning_rate': 'optimal', 'eta0': 0.0005}\n",
      "\t[ 6]: 0.695 (+/-0.047) for {'tol': 0.001, 'penalty': 'l2', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.005}\n",
      "\t[ 7]: 0.724 (+/-0.093) for {'tol': 0.0001, 'penalty': 'l1', 'max_iter': 10, 'learning_rate': 'optimal', 'eta0': 0.05}\n",
      "\t[ 8]: 0.714 (+/-0.085) for {'tol': 0.001, 'penalty': 'l2', 'max_iter': 1000, 'learning_rate': 'adaptive', 'eta0': 0.005}\n",
      "\t[ 9]: 0.724 (+/-0.093) for {'tol': 1e-05, 'penalty': 'l1', 'max_iter': 100, 'learning_rate': 'constant', 'eta0': 0.05}\n",
      "\t[10]: 0.371 (+/-0.038) for {'tol': 0.001, 'penalty': 'elasticnet', 'max_iter': 1, 'learning_rate': 'constant', 'eta0': 0.0005}\n",
      "\t[11]: 0.371 (+/-0.038) for {'tol': 0.001, 'penalty': 'l2', 'max_iter': 1000, 'learning_rate': 'invscaling', 'eta0': 0.0005}\n",
      "\t[12]: 0.695 (+/-0.047) for {'tol': 1e-05, 'penalty': 'l1', 'max_iter': 1, 'learning_rate': 'optimal', 'eta0': 0.05}\n",
      "\t[13]: 0.724 (+/-0.093) for {'tol': 0.001, 'penalty': 'l1', 'max_iter': 1000, 'learning_rate': 'optimal', 'eta0': 0.0005}\n",
      "\t[14]: 0.467 (+/-0.279) for {'tol': 1e-05, 'penalty': 'l2', 'max_iter': 1, 'learning_rate': 'invscaling', 'eta0': 0.005}\n",
      "\t[15]: 0.762 (+/-0.241) for {'tol': 0.001, 'penalty': 'elasticnet', 'max_iter': 10, 'learning_rate': 'constant', 'eta0': 0.005}\n",
      "\t[16]: 0.695 (+/-0.047) for {'tol': 1e-05, 'penalty': 'elasticnet', 'max_iter': 10000, 'learning_rate': 'invscaling', 'eta0': 0.05}\n",
      "\t[17]: 0.371 (+/-0.038) for {'tol': 1e-05, 'penalty': 'l2', 'max_iter': 10, 'learning_rate': 'invscaling', 'eta0': 0.0005}\n",
      "\t[18]: 0.952 (+/-0.060) for {'tol': 0.0001, 'penalty': 'l1', 'max_iter': 1000, 'learning_rate': 'adaptive', 'eta0': 0.05}\n",
      "\t[19]: 0.695 (+/-0.047) for {'tol': 0.0001, 'penalty': 'l2', 'max_iter': 10, 'learning_rate': 'optimal', 'eta0': 0.0005}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      0.83      0.91        18\n",
      "           2       0.79      1.00      0.88        11\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.93      0.94      0.93        45\n",
      "weighted avg       0.95      0.93      0.93        45\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(early_stopping=True, eta0=0.05, learning_rate='adaptive',\n",
      "              max_iter=100, penalty='elasticnet', random_state=42, tol=1e-05,\n",
      "              warm_start=True)\n",
      "\n",
      "best: dat=iris, score=0.95238, model=SGDClassifier(eta0=0.05,learning_rate='adaptive',max_iter=100,penalty='elasticnet',tol=1e-05)\n",
      "\n",
      "OK(grid-search)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marius\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "rand_tuned = RandomizedSearchCV(model,\n",
    "                                tuning_parameters,\n",
    "                                n_iter=20,\n",
    "                                cv=5,\n",
    "                                scoring='f1_micro',\n",
    "                                verbose=0,\n",
    "                                n_jobs=-1,\n",
    "                                random_state=42)\n",
    "rand_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "\n",
    "# Report result\n",
    "b0, m0 = FullReport(rand_tuned, X_test, y_test, t)\n",
    "print('OK(grid-search)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Qd MNIST Search Quest II\n",
    "\n",
    "Finally, a search-quest competition: __who can find the best model+hyperparameters for the MNIST dataset?__\n",
    "\n",
    "You change to the MNIST data by calling `LoadAndSetupData('mnist')`, and this is a completely other ball-game that the iris _tiny-data_: it's much larger (but still far from _big-data_)!\n",
    "\n",
    "* You might opt for the exhaustive grid search, or use the faster but-less optimal random search...your choice. \n",
    "\n",
    "* You are free to pick any classifier in Scikit-learn, even algorithms we have not discussed yet---__except Neural Networks and KNeighborsClassifier!__. \n",
    "\n",
    "* Keep the score function at `f1_micro`, otherwise, we will be comparing 'Ã¦bler og pÃ¦rer'. \n",
    "\n",
    "* And, you may also want to scale your input data for some models to perform better.\n",
    "\n",
    "* __REMEMBER__, DO NOT USE any Neural Network models. This also means not to use any `Keras` or `Tensorflow` models...since they outperform most other models, and there are also too many examples on the internet to cut-and-paste from!\n",
    "\n",
    "Check your result by printing the first _return_ value from `FullReport()` \n",
    "```python \n",
    "b1, m1 = FullReport(random_tuned , X_test, y_test, time_randomsearch)\n",
    "print(b1)\n",
    "```\n",
    "that will display a result like\n",
    "```\n",
    "best: dat=mnist, score=0.90780, model=SGDClassifier(alpha=1.0,eta0=0.0001,learning_rate='invscaling')\n",
    "```\n",
    "and paste your currently best model into the message box, for ITMAL group 09 like\n",
    "```\n",
    "Grp09: best: dat=mnist, score=0.90780, model=SGDClassifier(alpha=1.0,eta0=0.0001,learning_rate='invscaling')\n",
    "\n",
    "Grp09: CTOR for best model: SGDClassifier(alpha=1.0, average=False, class_weight=None, early_stopping=False,\n",
    "              epsilon=0.1, eta0=0.0001, fit_intercept=True, l1_ratio=0.15,\n",
    "              learning_rate='invscaling', loss='hinge', max_iter=1000,\n",
    "              n_iter_no_change=5, n_jobs=None, penalty='l2', power_t=0.5,\n",
    "              random_state=None, shuffle=True, tol=0.001,\n",
    "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "```\n",
    "              \n",
    "on Brightspace: \"L10: Regularisering, optimering og sÃ¸gning\" | \"Qd MNIST Search Quest II\"\n",
    "\n",
    ">  https://brightspace.au.dk/d2l/le/lessons/53939/topics/791969\n",
    "\n",
    "and, check if your score (for MNIST) is better than the currently best score. Republish if you get a better score than your own previously best.\n",
    "\n",
    "Remember to provide an ITMAL group name manually, so we can identify a winner: the 1. st price is  cake! \n",
    "\n",
    "For the journal hand-in, report your progress in scoring choosing different models, hyperparameters to search and how you might need to preprocess your data...and note, that the journal will not be accepted unless it contains information about Your results published on the Brightspace 'Search Quest II' page!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA: mnist..\n",
      "  org. data:  X.shape      =(70000;  784), y.shape      =(70000)\n",
      "  train data: X_train.shape=(49000;  784), y_train.shape=(49000)\n",
      "  test data:  X_test.shape =(21000;  784), y_test.shape =(21000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Setup data\n",
    "X_train, X_test, y_train, y_test = LoadAndSetupData(\n",
    "    'mnist')  # 'iris', 'moon', or 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEARCH TIME: 1568.69 sec\n",
      "\n",
      "Best model set found on train set:\n",
      "\n",
      "\tbest parameters={'warm_start': False, 'tol': 0.001, 'power_t': 0.1, 'penalty': 'l2', 'max_iter': 100, 'loss': 'perceptron', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.005, 'alpha': 1}\n",
      "\tbest 'f1_micro' score=0.8962448757990736\n",
      "\tbest index=179\n",
      "\n",
      "Best estimator CTOR:\n",
      "\tSGDClassifier(alpha=1, early_stopping=True, eta0=0.005, l1_ratio=0.3,\n",
      "              learning_rate='adaptive', loss='perceptron', max_iter=100,\n",
      "              power_t=0.1, random_state=42)\n",
      "\n",
      "Grid scores ('f1_micro') on development set:\n",
      "\t[ 0]: 0.552 (+/-0.027) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[ 1]: 0.099 (+/-0.001) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'learning_rate': 'constant', 'l1_ratio': 0.4, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[ 2]: 0.891 (+/-0.005) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.005, 'alpha': 0.01}\n",
      "\t[ 3]: 0.890 (+/-0.004) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'modified_huber', 'learning_rate': 'adaptive', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[ 4]: 0.890 (+/-0.005) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[ 5]: 0.860 (+/-0.020) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[ 6]: 0.878 (+/-0.008) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 100, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.4, 'eta0': 0.0005, 'alpha': 10}\n",
      "\t[ 7]: 0.896 (+/-0.005) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 1}\n",
      "\t[ 8]: 0.877 (+/-0.006) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.5, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.7, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\t[ 9]: 0.822 (+/-0.013) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.3, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 0.1}\n",
      "\t[10]: 0.878 (+/-0.010) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.3, 'penalty': 'l1', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 0.001}\n",
      "\t[11]: 0.890 (+/-0.004) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.8, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 0.0001}\n",
      "\t[12]: 0.833 (+/-0.033) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\t[13]: 0.096 (+/-0.008) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.4, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[14]: 0.103 (+/-0.012) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.7, 'eta0': 0.005, 'alpha': 1000}\n",
      "\t[15]: 0.099 (+/-0.001) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.1, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 100}\n",
      "\t[16]: 0.883 (+/-0.005) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[17]: 0.768 (+/-0.048) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.5, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.4, 'eta0': 0.0005, 'alpha': 10}\n",
      "\t[18]: 0.845 (+/-0.031) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.8, 'penalty': 'l2', 'max_iter': 100, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.3, 'eta0': 0.005, 'alpha': 0.001}\n",
      "\t[19]: 0.774 (+/-0.024) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\t[20]: 0.844 (+/-0.026) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'squared_hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.005, 'alpha': 100}\n",
      "\t[21]: 0.802 (+/-0.075) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'perceptron', 'learning_rate': 'constant', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[22]: 0.884 (+/-0.028) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[23]: 0.184 (+/-0.140) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.8, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[24]: 0.883 (+/-0.006) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.6, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[25]: 0.892 (+/-0.005) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.4, 'penalty': 'l1', 'max_iter': 100, 'loss': 'perceptron', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.001}\n",
      "\t[26]: 0.851 (+/-0.009) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 0.01}\n",
      "\t[27]: 0.877 (+/-0.015) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.5, 'penalty': 'elasticnet', 'max_iter': 10000, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[28]: 0.726 (+/-0.103) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[29]: 0.121 (+/-0.057) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'l1', 'max_iter': 100, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[30]: 0.890 (+/-0.005) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'l1', 'max_iter': 100, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[31]: 0.893 (+/-0.004) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 1000}\n",
      "\t[32]: 0.857 (+/-0.037) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.1, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'modified_huber', 'learning_rate': 'optimal', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[33]: 0.868 (+/-0.021) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.5, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'squared_hinge', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 0.01}\n",
      "\t[34]: 0.773 (+/-0.028) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 10}\n",
      "\t[35]: 0.869 (+/-0.008) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.1, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 0.1}\n",
      "\t[36]: 0.893 (+/-0.010) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.6, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[37]: 0.099 (+/-0.001) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.5, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[38]: 0.808 (+/-0.010) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.8, 'penalty': 'l1', 'max_iter': 100, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.4, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\t[39]: 0.894 (+/-0.004) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 0.01}\n",
      "\t[40]: 0.871 (+/-0.006) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.8, 'eta0': 0.005, 'alpha': 0.0001}\n",
      "\t[41]: 0.130 (+/-0.085) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[42]: 0.821 (+/-0.044) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.1, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[43]: 0.866 (+/-0.003) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.4, 'penalty': 'l2', 'max_iter': 100, 'loss': 'modified_huber', 'learning_rate': 'adaptive', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 10}\n",
      "\t[44]: 0.887 (+/-0.005) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'squared_hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[45]: 0.875 (+/-0.011) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.4, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[46]: 0.886 (+/-0.005) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 0.001}\n",
      "\t[47]: 0.126 (+/-0.070) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 10000, 'loss': 'log', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[48]: 0.152 (+/-0.061) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 10}\n",
      "\t[49]: 0.843 (+/-0.006) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[50]: 0.891 (+/-0.004) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.7, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[51]: 0.892 (+/-0.004) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.6, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'modified_huber', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 0.001}\n",
      "\t[52]: 0.890 (+/-0.011) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[53]: 0.882 (+/-0.007) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 0.01}\n",
      "\t[54]: 0.888 (+/-0.005) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'squared_hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 0.001}\n",
      "\t[55]: 0.183 (+/-0.065) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[56]: 0.868 (+/-0.027) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 10000, 'loss': 'modified_huber', 'learning_rate': 'optimal', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[57]: 0.865 (+/-0.013) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.4, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.3, 'eta0': 0.005, 'alpha': 1}\n",
      "\t[58]: 0.100 (+/-0.004) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.9, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 1000}\n",
      "\t[59]: 0.870 (+/-0.026) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.8, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[60]: 0.100 (+/-0.003) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.6, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'log', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 1000}\n",
      "\t[61]: 0.101 (+/-0.005) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[62]: 0.873 (+/-0.006) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'log', 'learning_rate': 'optimal', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[63]: 0.102 (+/-0.005) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.9, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[64]: 0.891 (+/-0.004) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.3, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[65]: 0.864 (+/-0.023) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 0.01}\n",
      "\t[66]: 0.868 (+/-0.018) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.1, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 0.0001}\n",
      "\t[67]: 0.879 (+/-0.005) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[68]: 0.866 (+/-0.039) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.4, 'penalty': 'l2', 'max_iter': 100, 'loss': 'squared_hinge', 'learning_rate': 'constant', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 0.0001}\n",
      "\t[69]: 0.893 (+/-0.004) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.5, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[70]: 0.516 (+/-0.100) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.5, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[71]: 0.858 (+/-0.021) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 0.1}\n",
      "\t[72]: 0.459 (+/-0.103) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'squared_hinge', 'learning_rate': 'constant', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[73]: 0.774 (+/-0.024) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\t[74]: 0.891 (+/-0.005) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.7, 'eta0': 0.005, 'alpha': 0.01}\n",
      "\t[75]: 0.891 (+/-0.004) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 0.0001}\n",
      "\t[76]: 0.890 (+/-0.007) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 0.01}\n",
      "\t[77]: 0.832 (+/-0.006) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[78]: 0.867 (+/-0.020) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 100, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[79]: 0.867 (+/-0.017) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.9, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 0.001}\n",
      "\t[80]: 0.890 (+/-0.003) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.1, 'penalty': 'l1', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.4, 'eta0': 0.005, 'alpha': 0.0001}\n",
      "\t[81]: 0.135 (+/-0.100) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 1000}\n",
      "\t[82]: 0.890 (+/-0.006) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.9, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[83]: 0.099 (+/-0.002) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.4, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[84]: 0.809 (+/-0.008) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.4, 'eta0': 0.005, 'alpha': 0.01}\n",
      "\t[85]: 0.112 (+/-0.000) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 100}\n",
      "\t[86]: 0.885 (+/-0.009) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.1, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[87]: 0.137 (+/-0.095) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.6, 'penalty': 'l1', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 10}\n",
      "\t[88]: 0.812 (+/-0.011) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\t[89]: 0.877 (+/-0.015) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[90]: 0.121 (+/-0.057) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.3, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 100}\n",
      "\t[91]: 0.870 (+/-0.026) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.1, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 0.0001}\n",
      "\t[92]: 0.863 (+/-0.005) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[93]: 0.491 (+/-0.155) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 10}\n",
      "\t[94]: 0.255 (+/-0.122) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.5, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 1000}\n",
      "\t[95]: 0.860 (+/-0.018) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.6, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'squared_hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[96]: 0.112 (+/-0.000) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[97]: 0.102 (+/-0.005) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[98]: 0.455 (+/-0.158) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.2, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 10}\n",
      "\t[99]: 0.856 (+/-0.028) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 0.0001}\n",
      "\t[100]: 0.869 (+/-0.016) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.3, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 0.001}\n",
      "\t[101]: 0.665 (+/-0.037) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'l1', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.7, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[102]: 0.867 (+/-0.006) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'squared_hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.8, 'eta0': 0.005, 'alpha': 1}\n",
      "\t[103]: 0.892 (+/-0.004) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\t[104]: 0.894 (+/-0.002) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.3, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'optimal', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 0.001}\n",
      "\t[105]: 0.890 (+/-0.006) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.5, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 0.01}\n",
      "\t[106]: 0.891 (+/-0.006) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'l1', 'max_iter': 100000, 'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[107]: 0.099 (+/-0.002) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[108]: 0.887 (+/-0.006) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[109]: 0.754 (+/-0.077) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.5, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[110]: 0.724 (+/-0.017) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[111]: 0.658 (+/-0.063) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.9, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[112]: 0.883 (+/-0.001) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'modified_huber', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\t[113]: 0.100 (+/-0.003) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.9, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[114]: 0.895 (+/-0.002) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 0.001}\n",
      "\t[115]: 0.871 (+/-0.006) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.1, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'perceptron', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.005, 'alpha': 0.001}\n",
      "\t[116]: 0.269 (+/-0.297) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[117]: 0.895 (+/-0.002) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.5, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 0.001}\n",
      "\t[118]: 0.883 (+/-0.006) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.6, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 0.0001}\n",
      "\t[119]: 0.112 (+/-0.000) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[120]: 0.101 (+/-0.004) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[121]: 0.096 (+/-0.008) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.5, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[122]: 0.156 (+/-0.047) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.1, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[123]: 0.868 (+/-0.012) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 0.001}\n",
      "\t[124]: 0.873 (+/-0.007) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 10000, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 0.001}\n",
      "\t[125]: 0.575 (+/-0.081) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.4, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[126]: 0.860 (+/-0.005) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'optimal', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[127]: 0.827 (+/-0.017) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.4, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[128]: 0.778 (+/-0.024) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 10}\n",
      "\t[129]: 0.562 (+/-0.029) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.8, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.3, 'eta0': 0.005, 'alpha': 1}\n",
      "\t[130]: 0.874 (+/-0.010) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'squared_hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[131]: 0.892 (+/-0.002) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.1, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[132]: 0.205 (+/-0.029) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[133]: 0.120 (+/-0.057) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'squared_hinge', 'learning_rate': 'constant', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[134]: 0.880 (+/-0.005) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 100, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[135]: 0.883 (+/-0.005) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.6, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[136]: 0.607 (+/-0.081) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.6, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 10}\n",
      "\t[137]: 0.848 (+/-0.036) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[138]: 0.873 (+/-0.006) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'log', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\t[139]: 0.817 (+/-0.013) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'adaptive', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[140]: 0.101 (+/-0.005) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.9, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[141]: 0.833 (+/-0.042) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.8, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'perceptron', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 0.01}\n",
      "\t[142]: 0.119 (+/-0.056) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.4, 'penalty': 'l1', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 10}\n",
      "\t[143]: 0.109 (+/-0.009) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 1000}\n",
      "\t[144]: 0.857 (+/-0.008) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[145]: 0.873 (+/-0.019) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[146]: 0.101 (+/-0.005) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'perceptron', 'learning_rate': 'adaptive', 'l1_ratio': 0.4, 'eta0': 0.0005, 'alpha': 100}\n",
      "\t[147]: 0.745 (+/-0.043) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[148]: 0.891 (+/-0.002) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.4, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'log', 'learning_rate': 'optimal', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[149]: 0.136 (+/-0.103) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.8, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 100}\n",
      "\t[150]: 0.516 (+/-0.100) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.4, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.005, 'alpha': 1}\n",
      "\t[151]: 0.112 (+/-0.000) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[152]: 0.878 (+/-0.018) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 0.001}\n",
      "\t[153]: 0.890 (+/-0.007) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 100000, 'loss': 'modified_huber', 'learning_rate': 'adaptive', 'l1_ratio': 0.5, 'eta0': 0.005, 'alpha': 0.001}\n",
      "\t[154]: 0.112 (+/-0.000) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'modified_huber', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[155]: 0.846 (+/-0.021) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.4, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'squared_hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 100}\n",
      "\t[156]: 0.109 (+/-0.009) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[157]: 0.756 (+/-0.018) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[158]: 0.853 (+/-0.021) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 10000, 'loss': 'modified_huber', 'learning_rate': 'adaptive', 'l1_ratio': 0.4, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[159]: 0.156 (+/-0.047) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.3, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[160]: 0.870 (+/-0.026) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.8, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[161]: 0.706 (+/-0.029) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.9, 'penalty': 'elasticnet', 'max_iter': 10000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[162]: 0.873 (+/-0.009) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[163]: 0.809 (+/-0.008) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.8, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[164]: 0.360 (+/-0.164) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'l2', 'max_iter': 100000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 1000}\n",
      "\t[165]: 0.742 (+/-0.046) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.5, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 1000}\n",
      "\t[166]: 0.099 (+/-0.001) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.5, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[167]: 0.121 (+/-0.057) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.9, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 100}\n",
      "\t[168]: 0.099 (+/-0.001) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.4, 'eta0': 0.005, 'alpha': 100}\n",
      "\t[169]: 0.836 (+/-0.042) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.4, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[170]: 0.099 (+/-0.001) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.4, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.005, 'alpha': 1000}\n",
      "\t[171]: 0.516 (+/-0.100) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'perceptron', 'learning_rate': 'optimal', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[172]: 0.136 (+/-0.104) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.6, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'constant', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 100}\n",
      "\t[173]: 0.891 (+/-0.004) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.5, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 0.01}\n",
      "\t[174]: 0.841 (+/-0.013) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.001}\n",
      "\t[175]: 0.840 (+/-0.005) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.9, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 0.01}\n",
      "\t[176]: 0.885 (+/-0.009) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'hinge', 'learning_rate': 'optimal', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 10}\n",
      "\t[177]: 0.101 (+/-0.004) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'squared_hinge', 'learning_rate': 'constant', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 1000}\n",
      "\t[178]: 0.840 (+/-0.044) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.1, 'penalty': 'elasticnet', 'max_iter': 10000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[179]: 0.896 (+/-0.002) for {'warm_start': False, 'tol': 0.001, 'power_t': 0.1, 'penalty': 'l2', 'max_iter': 100, 'loss': 'perceptron', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.005, 'alpha': 1}\n",
      "\t[180]: 0.133 (+/-0.098) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.3, 'penalty': 'elasticnet', 'max_iter': 10000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.0005, 'alpha': 100}\n",
      "\t[181]: 0.890 (+/-0.001) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'l2', 'max_iter': 100, 'loss': 'squared_hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.01}\n",
      "\t[182]: 0.205 (+/-0.029) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.6, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.3, 'eta0': 0.005, 'alpha': 10}\n",
      "\t[183]: 0.854 (+/-0.016) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.1, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'log', 'learning_rate': 'constant', 'l1_ratio': 0.8, 'eta0': 0.05, 'alpha': 0.001}\n",
      "\t[184]: 0.890 (+/-0.004) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.2, 'penalty': 'elasticnet', 'max_iter': 100, 'loss': 'squared_hinge', 'learning_rate': 'adaptive', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[185]: 0.690 (+/-0.034) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.7, 'penalty': 'l1', 'max_iter': 1000000, 'loss': 'modified_huber', 'learning_rate': 'optimal', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 1}\n",
      "\t[186]: 0.874 (+/-0.011) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.6, 'penalty': 'l1', 'max_iter': 100, 'loss': 'hinge', 'learning_rate': 'invscaling', 'l1_ratio': 0.7, 'eta0': 0.0005, 'alpha': 0.1}\n",
      "\t[187]: 0.855 (+/-0.021) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 0.0001}\n",
      "\t[188]: 0.863 (+/-0.005) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.7, 'penalty': 'elasticnet', 'max_iter': 1000000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 0.001}\n",
      "\t[189]: 0.238 (+/-0.012) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.9, 'penalty': 'elasticnet', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'constant', 'l1_ratio': 0.5, 'eta0': 0.05, 'alpha': 10}\n",
      "\t[190]: 0.822 (+/-0.020) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.5, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.7, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[191]: 0.411 (+/-0.106) for {'warm_start': False, 'tol': 1e-05, 'power_t': 0.3, 'penalty': 'l2', 'max_iter': 1000, 'loss': 'perceptron', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 100}\n",
      "\t[192]: 0.870 (+/-0.010) for {'warm_start': False, 'tol': 0.0001, 'power_t': 0.2, 'penalty': 'l2', 'max_iter': 100, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.8, 'eta0': 0.005, 'alpha': 0.001}\n",
      "\t[193]: 0.894 (+/-0.002) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'l1', 'max_iter': 10000, 'loss': 'modified_huber', 'learning_rate': 'optimal', 'l1_ratio': 0.4, 'eta0': 0.0005, 'alpha': 0.001}\n",
      "\t[194]: 0.860 (+/-0.003) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.3, 'penalty': 'l2', 'max_iter': 100, 'loss': 'modified_huber', 'learning_rate': 'adaptive', 'l1_ratio': 0.8, 'eta0': 0.0005, 'alpha': 100}\n",
      "\t[195]: 0.677 (+/-0.090) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.1, 'penalty': 'l2', 'max_iter': 100, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.05, 'alpha': 0.1}\n",
      "\t[196]: 0.791 (+/-0.053) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.6, 'penalty': 'l2', 'max_iter': 10000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.6, 'eta0': 0.005, 'alpha': 100}\n",
      "\t[197]: 0.887 (+/-0.005) for {'warm_start': True, 'tol': 0.001, 'power_t': 0.6, 'penalty': 'l1', 'max_iter': 1000, 'loss': 'modified_huber', 'learning_rate': 'invscaling', 'l1_ratio': 0.3, 'eta0': 0.0005, 'alpha': 0.0001}\n",
      "\t[198]: 0.885 (+/-0.005) for {'warm_start': True, 'tol': 0.0001, 'power_t': 0.3, 'penalty': 'l2', 'max_iter': 1000000, 'loss': 'log', 'learning_rate': 'adaptive', 'l1_ratio': 0.4, 'eta0': 0.05, 'alpha': 1}\n",
      "\t[199]: 0.794 (+/-0.014) for {'warm_start': True, 'tol': 1e-05, 'power_t': 0.9, 'penalty': 'elasticnet', 'max_iter': 10000, 'loss': 'log', 'learning_rate': 'invscaling', 'l1_ratio': 0.4, 'eta0': 0.005, 'alpha': 0.1}\n",
      "\n",
      "Detailed classification report:\n",
      "\tThe model is trained on the full development set.\n",
      "\tThe scores are computed on the full evaluation set.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      2077\n",
      "           1       0.93      0.96      0.94      2385\n",
      "           2       0.93      0.86      0.89      2115\n",
      "           3       0.88      0.87      0.88      2117\n",
      "           4       0.84      0.95      0.89      2004\n",
      "           5       0.79      0.87      0.83      1900\n",
      "           6       0.93      0.94      0.94      2045\n",
      "           7       0.88      0.93      0.90      2189\n",
      "           8       0.90      0.76      0.82      2042\n",
      "           9       0.90      0.79      0.84      2126\n",
      "\n",
      "    accuracy                           0.89     21000\n",
      "   macro avg       0.89      0.89      0.89     21000\n",
      "weighted avg       0.89      0.89      0.89     21000\n",
      "\n",
      "\n",
      "CTOR for best model: SGDClassifier(alpha=1, early_stopping=True, eta0=0.005, l1_ratio=0.3,\n",
      "              learning_rate='adaptive', loss='perceptron', max_iter=100,\n",
      "              power_t=0.1, random_state=42)\n",
      "\n",
      "best: dat=mnist, score=0.89624, model=SGDClassifier(alpha=1,eta0=0.005,l1_ratio=0.3,learning_rate='adaptive',loss='perceptron',max_iter=100,penalty='l2',power_t=0.1,tol=0.001,warm_start=False)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marius\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass labels=None as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "# Setup search parameters\n",
    "model = SGDClassifier( eta0=0.05,\n",
    "                       early_stopping=True,\n",
    "                       random_state=42)\n",
    "\n",
    "tuning_parameters = {\n",
    "    'l1_ratio': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8],\n",
    "    'power_t': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "    'eta0': [0.0005, 0.005, 0.05],\n",
    "    'learning_rate': ('constant', 'invscaling', 'adaptive', 'optimal'),\n",
    "    'warm_start': [True, False],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    'max_iter': [100, 1000, 10000, 100000, 1000000],\n",
    "    'penalty': ('l2', 'l1', 'elasticnet'),\n",
    "    'tol': [0.001, 0.0001, 0.00001],\n",
    "    'loss': ('modified_huber', 'squared_hinge', 'perceptron', 'hinge', 'log')\n",
    "}\n",
    "\n",
    "# Run GridSearchCV for the model\n",
    "start = time()\n",
    "random_tuned = RandomizedSearchCV(model,\n",
    "                          tuning_parameters,\n",
    "                          cv=3,\n",
    "                          scoring='f1_micro',\n",
    "                          verbose=0,\n",
    "                          n_jobs=10,\n",
    "                          n_iter=200)\n",
    "random_tuned.fit(X_train, y_train)\n",
    "t = time() - start\n",
    "# Report result\n",
    "b0, m0 = FullReport(random_tuned, X_test, y_test, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REVISIONS||\n",
    "---------||\n",
    "2018-03-01| CEF, initial.\n",
    "2018-03-05| CEF, updated.\n",
    "2018-03-06| CEF, updated and spell checked.\n",
    "2018-03-06| CEF, major overhaul of functions.\n",
    "2018-03-06| CEF, fixed problem with MNIST load and Keras.\n",
    "2018-03-07| CEF, modified report functions and changed Qc+d.\n",
    "2018-03-11| CEF, updated Qd.\n",
    "2018-03-12| CEF, added grid and random search figs and added bullets to Qd.\n",
    "2018-03-13| CEF, fixed SVC and gamma issue, and changed dataload to be in fetchmode (non-keras).\n",
    "2019-10-15| CEF, updated for ITMAL E19\n",
    "2019-10-19| CEF, minor text update.\n",
    "2019-10-23| CEF, changed demo model i Qd) from MLPClassifier to SVC.\n",
    "2020-03-14| CEF, updated to ITMAL F20.\n",
    "2020-10-20| CEF, updated to ITMAL E20.\n",
    "2020-10-27| CEF, type fixes and minor update.\n",
    "2020-10-28| CEF, added extra journal hand-in specs for Search Quest II, Qd.\n",
    "2020-10-30| CEF, added non-use of KNeighborsClassifier to Search Quest II, Qd.\n",
    "2020-11-19| CEF, changed load_mode=2 (Keras) to load_mode=0 (auto) for MNIST loader.\n",
    "2021-03-17| CEF, updated to ITMAL F21.\n",
    "2021-10-31| CEF, updated to ITMAL E21.\n",
    "2021-11-05| CEF, removed iid=True paramter from GridSearchCV(), not present in current version of Scikit-learn (0.24.1).\n",
    "2022-03-31| CEF, updated to SWMAL F22.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
